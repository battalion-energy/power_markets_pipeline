#!/usr/bin/env python3
"""
Complete BESS Revenue Analysis
Processes 60-day disclosure data to calculate comprehensive revenues
"""

import pandas as pd
import numpy as np
from pathlib import Path
import glob
from datetime import datetime
import os

# Paths
DAM_DIR = Path("/Users/enrico/data/ERCOT_data/60-Day_DAM_Disclosure_Reports/csv")
SCED_DIR = Path("/Users/enrico/data/ERCOT_data/60-Day_SCED_Disclosure_Reports/csv")
PRICE_DIR = Path("annual_output/Settlement_Point_Prices_at_Resource_Nodes__Hubs_and_Load_Zones")
OUTPUT_DIR = Path("bess_complete_analysis")
OUTPUT_DIR.mkdir(exist_ok=True)

# Load BESS master list
print("ğŸ“‹ Loading BESS resources...")
bess_df = pd.read_csv("bess_analysis/bess_resources_master_list.csv")
bess_resources = {row['Resource_Name']: row for _, row in bess_df.iterrows()}
print(f"   Found {len(bess_resources)} BESS resources")

def process_year(year):
    """Process all data for a given year"""
    print(f"\nğŸ“… Processing year {year}")
    
    # Initialize results
    results = []
    
    # Get DAM files for this year
    dam_pattern = f"*DAM_Gen_Resource_Data*{year % 100:02d}.csv"
    dam_files = list(DAM_DIR.glob(dam_pattern))
    print(f"   Found {len(dam_files)} DAM files")
    
    # Get SCED files for this year
    sced_pattern = f"*SCED_Gen_Resource_Data*{year % 100:02d}.csv"
    sced_files = list(SCED_DIR.glob(sced_pattern))
    print(f"   Found {len(sced_files)} SCED files")
    
    # Initialize revenue accumulators
    revenues = {}
    for name in bess_resources:
        revenues[name] = {
            'rt_energy': 0.0,
            'dam_energy': 0.0,
            'reg_up': 0.0,
            'reg_down': 0.0,
            'spin': 0.0,  # RRS
            'non_spin': 0.0,
            'ecrs': 0.0
        }
    
    # Process DAM files
    print("   Processing DAM data...")
    for file in dam_files[:5]:  # Process first 5 files as sample
        try:
            df = pd.read_csv(file)
            
            # Filter for BESS
            bess_data = df[df['Resource Type'] == 'PWRSTR'].copy()
            if len(bess_data) == 0:
                continue
                
            # Energy revenue
            if 'Awarded Quantity' in bess_data.columns and 'Energy Settlement Point Price' in bess_data.columns:
                bess_data['dam_revenue'] = pd.to_numeric(bess_data['Awarded Quantity'], errors='coerce') * \
                                          pd.to_numeric(bess_data['Energy Settlement Point Price'], errors='coerce')
                
                for name in bess_data['Resource Name'].unique():
                    if name in revenues:
                        revenues[name]['dam_energy'] += bess_data[bess_data['Resource Name'] == name]['dam_revenue'].sum()
            
            # AS revenues
            as_services = {
                'RegUp Awarded': ('RegUp MCPC', 'reg_up'),
                'RegDown Awarded': ('RegDown MCPC', 'reg_down'),
                'ECRSSD Awarded': ('ECRS MCPC', 'ecrs'),
                'NonSpin Awarded': ('NonSpin MCPC', 'non_spin')
            }
            
            for award_col, (price_col, revenue_key) in as_services.items():
                if award_col in bess_data.columns and price_col in df.columns:
                    bess_data[f'{revenue_key}_revenue'] = pd.to_numeric(bess_data[award_col], errors='coerce') * \
                                                          pd.to_numeric(bess_data[price_col], errors='coerce')
                    
                    for name in bess_data['Resource Name'].unique():
                        if name in revenues:
                            revenues[name][revenue_key] += bess_data[bess_data['Resource Name'] == name][f'{revenue_key}_revenue'].sum()
            
            # RRS (Spin) - combine all RRS types
            rrs_types = ['RRSPFR Awarded', 'RRSFFR Awarded', 'RRSUFR Awarded']
            if 'RRS MCPC' in df.columns:
                for rrs_col in rrs_types:
                    if rrs_col in bess_data.columns:
                        bess_data['rrs_revenue'] = pd.to_numeric(bess_data[rrs_col], errors='coerce') * \
                                                  pd.to_numeric(bess_data['RRS MCPC'], errors='coerce')
                        
                        for name in bess_data['Resource Name'].unique():
                            if name in revenues:
                                revenues[name]['spin'] += bess_data[bess_data['Resource Name'] == name]['rrs_revenue'].sum()
                        
        except Exception as e:
            print(f"      Error processing {file.name}: {e}")
    
    # Load RT prices (sample)
    print("   Loading RT prices...")
    price_file = PRICE_DIR / f"Settlement_Point_Prices_at_Resource_Nodes__Hubs_and_Load_Zones_{year}.parquet"
    rt_prices = {}
    
    if price_file.exists():
        try:
            price_df = pd.read_parquet(price_file)
            # Create price lookup (simplified - would need proper time matching)
            for _, row in price_df.iterrows():
                sp = row['SettlementPointName']
                price = row['SettlementPointPrice']
                rt_prices[sp] = price  # Simplified - should be by timestamp
        except:
            pass
    
    # Process SCED files (sample)
    print("   Processing SCED data...")
    for file in sced_files[:2]:  # Process first 2 files as sample
        try:
            # Read in chunks due to large size
            for chunk in pd.read_csv(file, chunksize=50000):
                bess_data = chunk[chunk['Resource Type'] == 'PWRSTR'].copy()
                if len(bess_data) == 0:
                    continue
                
                # RT revenue calculation (simplified)
                for name in bess_data['Resource Name'].unique():
                    if name in revenues and name in bess_resources:
                        sp = bess_resources[name].get('Settlement_Point', '')
                        if sp in rt_prices:
                            base_points = pd.to_numeric(bess_data[bess_data['Resource Name'] == name]['Base Point'], errors='coerce')
                            # RT revenue = MW * $/MWh * hours (5 min = 1/12 hour)
                            revenues[name]['rt_energy'] += base_points.sum() * rt_prices[sp] * (5/60)
                            
        except Exception as e:
            print(f"      Error processing {file.name}: {e}")
    
    # Create results
    for name, rev in revenues.items():
        total = sum(rev.values())
        if total > 0:  # Only include resources with revenue
            results.append({
                'BESS_Asset_Name': name,
                'Year': year,
                'RT_Revenue': rev['rt_energy'],
                'DA_Revenue': rev['dam_energy'],
                'Spin_Revenue': rev['spin'],
                'NonSpin_Revenue': rev['non_spin'],
                'RegUp_Revenue': rev['reg_up'],
                'RegDown_Revenue': rev['reg_down'],
                'ECRS_Revenue': rev['ecrs'],
                'Total_Revenue': total
            })
    
    return results

# Get available years
print("\nğŸ” Finding available years...")
years = set()
for file in DAM_DIR.glob("*DAM_Gen_Resource_Data*.csv"):
    # Extract year from filename
    parts = file.stem.split('-')
    if len(parts) >= 3:
        year_str = parts[-1]
        try:
            year_val = int(year_str)
            if year_val < 50:
                years.add(2000 + year_val)
            else:
                years.add(1900 + year_val)
        except:
            pass

years = sorted(list(years))
print(f"   Years available: {years}")

# Process each year
all_results = []
for year in years[-3:]:  # Process last 3 years as example
    year_results = process_year(year)
    all_results.extend(year_results)

# Create final dataframe
print("\nğŸ’¾ Saving results...")
if all_results:
    results_df = pd.DataFrame(all_results)
    
    # Save to CSV
    csv_path = OUTPUT_DIR / "bess_annual_revenues_complete.csv"
    results_df.to_csv(csv_path, index=False)
    
    # Save to Parquet
    parquet_path = OUTPUT_DIR / "bess_annual_revenues_complete.parquet"
    results_df.to_parquet(parquet_path, index=False)
    
    print(f"\nâœ… Saved results to:")
    print(f"   - {csv_path}")
    print(f"   - {parquet_path}")
    
    # Print summary
    print("\nğŸ“Š BESS Revenue Summary")
    print("=" * 80)
    print(f"{'Year':<6} {'Resources':<12} {'Total($M)':<15} {'RT($M)':<12} {'DAM($M)':<12} {'AS($M)':<12}")
    print("-" * 80)
    
    for year in results_df['Year'].unique():
        year_data = results_df[results_df['Year'] == year]
        total_rev = year_data['Total_Revenue'].sum() / 1e6
        rt_rev = year_data['RT_Revenue'].sum() / 1e6
        dam_rev = year_data['DA_Revenue'].sum() / 1e6
        as_rev = (year_data['Spin_Revenue'].sum() + year_data['NonSpin_Revenue'].sum() + 
                  year_data['RegUp_Revenue'].sum() + year_data['RegDown_Revenue'].sum() + 
                  year_data['ECRS_Revenue'].sum()) / 1e6
        n_resources = len(year_data)
        
        print(f"{year:<6} {n_resources:<12} {total_rev:<15.2f} {rt_rev:<12.2f} {dam_rev:<12.2f} {as_rev:<12.2f}")
    
    # Show sample records
    print("\nğŸ“‹ Sample BESS Revenue Records:")
    print(results_df.head(10).to_string(index=False))
    
else:
    print("\nâŒ No results generated")

print("\nâœ… Analysis complete!")